{"cells":[{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":483,"status":"ok","timestamp":1640108186446,"user":{"displayName":"Rex Lui","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaWl3f0wDql7DVFD5E4BNGygMDkDdG13x2C2BrLg=s64","userId":"14957755385995550478"},"user_tz":-480},"id":"AdKl5wRIEJhF"},"outputs":[],"source":["#Import necessary package\n","import requests\n","import re\n","from bs4 import BeautifulSoup\n","import json\n","import pandas as pd\n","import numpy as np\n","import datetime as dt"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1640108186447,"user":{"displayName":"Rex Lui","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaWl3f0wDql7DVFD5E4BNGygMDkDdG13x2C2BrLg=s64","userId":"14957755385995550478"},"user_tz":-480},"id":"vavfgn0wEJhK"},"outputs":[],"source":["#Configure parameter\n","mall = 'K11Musea'\n","shoplisturl = 'https://k11musea.com/shop'\n","fnblisturl = 'https://k11musea.com/taste'\n","shopdetaibasiclurl = 'https://k11musea.com'\n","shoplistapi = 'https://www.k11musea.com/Api/Frontend/GetShops?language=en-gb'\n","shoplisttcapi = 'https://www.k11musea.com/Api/Frontend/GetShops?language=zh-hk'\n","fnblistapi = 'https://www.k11musea.com/Api/Frontend/GetRestaurants?language=en-gb'\n","fnblisttcapi = 'https://www.k11musea.com/Api/Frontend/GetRestaurants?language=zh-hk'"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["#Get shop category data and export into csv\n","def getShopCategory():\n","    #Create empty DataFrame for shop category\n","    shopcategory = pd.DataFrame()\n","    for type, url in zip(['Shopping','Dining'],[shoplisturl,fnblisturl]):\n","        #Get shop category\n","        page = requests.get(url)\n","        soup = BeautifulSoup(page.content, 'html.parser')\n","        for tab in soup.find_all(class_ = 'tab-content', attrs = {'data-tab-id':'category_id'}):\n","            for tabtext in tab.find_all('div', class_ = 'tab-text'):\n","                try:\n","                    shop_category_id = tabtext.get('data-category-id')\n","                except:\n","                    shop_category_id = np.nan\n","\n","                try:\n","                    shop_category_name = tabtext.text\n","                except:\n","                    shop_category_name = np.nan\n","\n","                shopcategory = shopcategory.append(\n","                        {\n","                            'type':type,\n","                            'shop_category_id':shop_category_id,\n","                            'shop_category_name':shop_category_name\n","                            }, ignore_index=True\n","                            )\n","    shopcategory['update_date'] = dt.date.today()\n","    shopcategory['mall'] = mall\n","    shopcategory.drop(shopcategory[shopcategory.shop_category_id == 'all'].index, inplace = True)\n","    shopcategory = shopcategory.loc[:, ['mall','type','shop_category_id','shop_category_name','update_date']]\n","    return shopcategory"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["#Get shop master data and export into csv\n","def getShopMaster():\n","    shopcategory = getShopCategory()\n","    #Create empty DataFrame for shop master\n","    shoplist = pd.DataFrame()\n","    shoplisttc = pd.DataFrame()\n","    shopdetail = pd.DataFrame()\n","\n","    #Create floor mapping\n","    floor_list = ['B2F','B1F','GF','1F','2F','3F','4F','5F','6F','7F','8F','9F','10F']\n","\n","    for type, api, tcapi in zip(['Shopping','Dining'],[shoplistapi,fnblistapi],[shoplisttcapi,fnblisttcapi]):\n","        shoplistrequest = requests.get(api)\n","        shoplistresponse = json.loads(shoplistrequest.content)\n","        for shop in shoplistresponse['items']:\n","            try:\n","                shop_id = shop['guid']\n","            except:\n","                shop_id = np.nan\n","\n","            try:\n","                shop_name = shop['name']\n","            except:\n","                shop_name = np.nan\n","\n","            try:\n","                exist = set()\n","                exist_add = exist.add\n","                shop_location = shop['location'].replace('(10/F)',', 10F')\n","                shop_location_split = [parts.strip().replace('/','') for parts in shop_location.split(',')]\n","                shop_location_split = [element.replace('B1','B1F').replace('B2','B2F') for element in shop_location_split]\n","                shop_location_split = [x for x in shop_location_split if not (x in exist or exist_add(x))]\n","                shop_floor = ';'.join([parts for parts in shop_location_split if parts in floor_list])\n","                shop_location_split.remove(shop_floor)\n","                shop_number = ';'.join(shop_location_split)\n","\n","            except:\n","                shop_location = np.nan\n","                shop_floor = np.nan\n","                shop_number = np.nan\n","\n","            try:\n","                shop_tag = shop['tag']\n","            except:\n","                shop_tag = np.nan\n","\n","            try:\n","                shop_detaillink = shop['umbraco_link']\n","            except:\n","                shop_detaillink = np.nan\n","\n","            shoplist = shoplist.append(\n","                    {\n","                        'type':type,\n","                        'shop_id':shop_id,\n","                        'shop_name_en': shop_name,\n","                        'tag': shop_tag,\n","                        'shop_number':shop_number,\n","                        'shop_floor':shop_floor,\n","                        'shop_detaillink':shop_detaillink\n","                        }, ignore_index=True\n","                        )\n","\n","        shoplisttcrequest = requests.get(tcapi)\n","        shoplisttcresponse = json.loads(shoplisttcrequest.content)\n","        for shop in shoplisttcresponse['items']:\n","            try:\n","                shop_id = shop['guid']\n","            except:\n","                shop_id = np.nan\n","\n","            try:\n","                shop_name_zh = shop['name']\n","            except:\n","                shop_name_zh = np.nan\n","\n","            shoplisttc = shoplisttc.append(\n","                    {\n","                        'type':type,\n","                        'shop_id':shop_id,\n","                        'shop_name_tc': shop_name_zh\n","                        }, ignore_index=True\n","                        )\n","\n","    for shopdetaillink in shoplist['shop_detaillink']:\n","        shopdetailurl = shopdetaibasiclurl + shopdetaillink\n","        page = requests.get(shopdetailurl)\n","        soup = BeautifulSoup(page.content, 'html.parser')\n","\n","        try:\n","            phone = soup.find('div', class_ = 'icon-phone').find_parent().find_next_sibling('div').find(class_ = 'twsi__info-content-text').text\n","            phone = phone.replace(' ','').replace('\\t','')\n","        except:\n","            phone = np.nan\n","\n","        try:\n","            opening_hours = soup.find('div', class_ = 'icon-clock').find_parent().find_next_sibling('div').find(class_ = 'twsi__info-content-text').text\n","        except:\n","            opening_hours = np.nan\n","        \n","        try:\n","            loyalty_offer = soup.find('div', class_ = 'twsi__kdollar-text').text\n","        except:\n","            loyalty_offer = np.nan\n","\n","        try:\n","            shop_category_list = [cat.text for cat in soup.find('div', class_ = 'twsi__tag').find_all(class_ = 'twsi__tag-item')]\n","            shop_category_list = ['Fashion' if item == 'Fashion & Accessories' else item for item in shop_category_list]\n","            shop_category_name = ';'.join(shop_category_list)\n","\n","            shop_category_id_list = [shopcategory.loc[shopcategory['shop_category_name'] == cat, 'shop_category_id'].values[0] for cat in shop_category_list]\n","            shop_category_id = ';'.join(shop_category_id_list)\n","        except:\n","            shop_category_name = np.nan\n","            shop_category_id = np.nan\n","        \n","        shopdetail = shopdetail.append(\n","                    {\n","                        'shop_detaillink':shopdetaillink,\n","                        'phone': phone,\n","                        'opening_hours': opening_hours,\n","                        'loyalty_offer':loyalty_offer,\n","                        'shop_category_id':shop_category_id,\n","                        'shop_category_name':shop_category_name\n","                        }, ignore_index=True\n","                        )\n","        \n","    #Merge shop list and shop detail into shop master\n","    shoplist = pd.merge(shoplist, shoplisttc, on = ['type','shop_id'])\n","    shopmaster = pd.merge(shoplist, shopdetail, on = 'shop_detaillink')\n","    shopmaster['update_date'] = dt.date.today()\n","    shopmaster['mall'] = mall\n","    shopmaster['voucher_acceptance'] = np.nan\n","    shopmaster = shopmaster.loc[:, ['mall','type','shop_id','shop_name_en','shop_name_tc','shop_number','shop_floor','phone','opening_hours','loyalty_offer','voucher_acceptance','shop_category_id','shop_category_name','tag','update_date']]\n","    return shopmaster"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["#Export data to csv\n","shopcategory = getShopCategory()\n","shopcategory.to_csv('{}_shopcategory_{}.csv'.format(mall,dt.date.strftime(dt.date.today(),'%Y%m%d')), index = False)\n","\n","shopmaster = getShopMaster()\n","shopmaster.to_csv('{}_shopmaster_{}.csv'.format(mall,dt.date.strftime(dt.date.today(),'%Y%m%d')), index = False)"]}],"metadata":{"colab":{"name":"TimeSquare_WebScraping_ShopDirectory.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
