{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":483,"status":"ok","timestamp":1640108186446,"user":{"displayName":"Rex Lui","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaWl3f0wDql7DVFD5E4BNGygMDkDdG13x2C2BrLg=s64","userId":"14957755385995550478"},"user_tz":-480},"id":"AdKl5wRIEJhF"},"outputs":[],"source":["#Import necessary package\n","import requests\n","import re\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import numpy as np\n","import datetime as dt"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1640108186447,"user":{"displayName":"Rex Lui","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaWl3f0wDql7DVFD5E4BNGygMDkDdG13x2C2BrLg=s64","userId":"14957755385995550478"},"user_tz":-480},"id":"vavfgn0wEJhK"},"outputs":[],"source":["#Configure parameter\n","mall = 'TheOne'\n","shoplisturl = 'https://www.the-one.hk/en/shopdirectory/shoplist.asp'\n","fnblisturl = ''\n","shopdetailbasicurl = 'https://www.the-one.hk/en/shopdirectory/shopdetails.asp?id='\n","shopdetailbasictcurl = 'https://www.the-one.hk/tc/shopdirectory/shopdetails.asp?id='"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#Get shop category data and export into csv\n","def getShopCategory():\n","    #Create empty DataFrame for shop category\n","    shopcategory = pd.DataFrame()\n","\n","    url = shoplisturl\n","    page = requests.get(url)\n","    soup = BeautifulSoup(page.content, 'html.parser')\n","\n","    for i in soup.find_all(class_ = 'selectAllCat'):\n","        for j in i.find_all('option'):\n","            if j.get('value') == None:\n","                pass\n","            else:\n","                try:\n","                    shop_category_id = j.get('value')\n","                except:\n","                        shop_category_id = np.nan\n","\n","                try:\n","                    shop_category_name = j.text\n","                except:\n","                        shop_category_name = np.nan\n","\n","                shopcategory = shopcategory.append(\n","                    {\n","                        'type':type,\n","                        'shop_category_id':shop_category_id,\n","                        'shop_category_name':shop_category_name\n","                        }, ignore_index=True\n","                        )\n","    shopcategory['update_date'] = dt.date.today()\n","    shopcategory['mall'] = mall\n","    shopcategory['type'] = shopcategory['shop_category_name'].apply(lambda x: 'Dining' if any(keyword in x.lower() for keyword in ['food','dining']) else 'Shopping')\n","    shopcategory = shopcategory.loc[:, ['mall','type','shop_category_id','shop_category_name','update_date']]\n","    return shopcategory"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#Get shop master data and export into csv\n","def getShopMaster():\n","    shopcategory = getShopCategory()\n","    #Create empty DataFrame for shop master\n","    shoplist = pd.DataFrame()\n","    shopdetail = pd.DataFrame()\n","    \n","    url = shoplisturl\n","    page = requests.get(url)\n","    soup = BeautifulSoup(page.content, 'html.parser')\n","    \n","    for shop in soup.find_all(class_ = 'shopEntry'):\n","        for shopbrand in shop.find(class_ = 'shopEntryBrand'):\n","            try:\n","                shopbrandlink = shopbrand.get('href')\n","                shopbrandlinkid = shopbrandlink.find('?id=')\n","                shop_id = shopbrandlink[shopbrandlinkid+4:]\n","            except:\n","                shop_id = np.nan\n","            \n","            try:\n","                shop_name = shopbrand.text\n","            except:\n","                shop_name = np.nan\n","        \n","        try:\n","            shop_number = shop.find(class_ = 'shopEntryLocation').text\n","        except:\n","            shop_number = np.nan\n","        \n","        try:\n","            shop_floor = shop.find(class_ = 'shopEntryFloor').text.replace(' ','')\n","        except:\n","            shop_floor = np.nan\n","        \n","        try:\n","            shop_category_name = shop.find(class_ = 'shopEntryCategory').text\n","        except:\n","            shop_category_name = np.nan\n","    \n","        try:\n","            shop_category_id = shopcategory.loc[shopcategory['shop_category_name'] == shop_category_name, 'shop_category_id'].values[0]\n","        except:\n","            shop_category_id = np.nan\n","    \n","        try:\n","            if shop.find(class_ = 'shopEntryCard').find_all(src = re.compile('ico_the_one_card')):\n","                loyalty_offer = 'The ONE Card'\n","            else:\n","                loyalty_offer = np.nan\n","        except:\n","            loyalty_offer = np.nan\n","    \n","        try:\n","            if shop.find(class_ = 'shopEntryCard').find_all(src = re.compile('ico_cash_coupon')):\n","                voucher_acceptance = '1'\n","            else:\n","                voucher_acceptance = np.nan\n","        except:\n","            voucher_acceptance = np.nan\n","        \n","        shoplist = shoplist.append(\n","                    {\n","                        'shop_id':shop_id,\n","                        'shop_name_en': shop_name,\n","                        'shop_number':shop_number,\n","                        'shop_floor':shop_floor,\n","                        'shop_category_id':shop_category_id,\n","                        'shop_category_name':shop_category_name,\n","                        'loyalty_offer':loyalty_offer,\n","                        'voucher_acceptance':voucher_acceptance\n","                        }, ignore_index=True\n","                        )\n","    #Get shop detail\n","    for shop_id in shoplist['shop_id']:\n","        shopdetailurl = shopdetailbasictcurl + shop_id\n","        page = requests.get(shopdetailurl)\n","        soup = BeautifulSoup(page.content, 'html.parser')\n","    \n","        for shopdetailinner in soup.find_all(class_ = 'shopDetailsInner'):\n","            try:\n","                shop_name_zh = shopdetailinner.find('span').text\n","            except:\n","                shop_name_zh = np.nan\n","        \n","        shopdetailurl = shopdetailbasicurl + shop_id\n","        page = requests.get(shopdetailurl)\n","        soup = BeautifulSoup(page.content, 'html.parser')\n","    \n","        for shopdetailcontent in soup.find_all(class_ = 'shopDetailsContent'):\n","            try:\n","                phone = shopdetailcontent.find('th', text = 'Telephone').find_next_sibling('td').find_next_sibling('td').text\n","                phone = phone.replace(' ','').replace('\\n','').replace('\\r','').replace('<br>','')\n","            except:\n","                phone = np.nan\n","            \n","            try:\n","                opening_hours = shopdetailcontent.find('th', text = 'Opening Time').find_next_sibling('td').find_next_sibling('td').text\n","                opening_hours = opening_hours = opening_hours.replace('\\n','').replace('\\r','').replace('<br>','')\n","            except:\n","                opening_hours = np.nan\n","                \n","        shopdetail = shopdetail.append(\n","                    {\n","                        'shop_id':shop_id,\n","                        'shop_name_tc':shop_name_zh,\n","                        'phone': phone,\n","                        'opening_hours': opening_hours\n","                        }, ignore_index=True\n","                        )\n","    \n","    #Merge shop list and shop detail into shop master\n","    shopmaster = pd.merge(shoplist, shopdetail, on = 'shop_id')\n","    shopmaster['update_date'] = dt.date.today()\n","    shopmaster['mall'] = mall\n","    shopmaster['type'] = shopmaster['shop_category_name'].apply(lambda x: 'Dining' if any(keyword in x.lower() for keyword in ['food','dining']) else 'Shopping')\n","    shopmaster['fnb_zone'] = np.nan\n","    shopmaster = shopmaster.loc[:, ['mall','type','shop_id','shop_name_en','shop_name_tc','fnb_zone','shop_number','shop_floor','phone','opening_hours','loyalty_offer','voucher_acceptance','shop_category_id','shop_category_name','update_date']]\n","    return shopmaster"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["#Export data to csv\n","shopcategory = getShopCategory()\n","shopcategory.to_csv('{}_shopcategory_{}.csv'.format(mall,dt.date.strftime(dt.date.today(),'%Y%m%d')), index = False)\n","\n","shopmaster = getShopMaster()\n","shopmaster.to_csv('{}_shopmaster_{}.csv'.format(mall,dt.date.strftime(dt.date.today(),'%Y%m%d')), index = False)"]}],"metadata":{"colab":{"name":"TimeSquare_WebScraping_ShopDirectory.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}
